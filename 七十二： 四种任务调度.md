# schedule/crontab/apschedule/celery 四种任务调度方式
## 一：简介及对比
     1）schedule -- 
			schdule库是一个轻量级的定时任务库，类似于linux的cron，使用简单，但是并不支
         持任务持久化以及动态操作，一般用于小型应用程序；
	 2) crontab -- 
	        linux系统是由crond系统服务来控制的，原本就有很多计划性工作，因此这个系统服务是在
         /etc/init.d中默认启动的守护进程，也为使用者提供了计划任务的命令： crontab 命令；
		
		    crond是linux下周期性执行任务的一个守护进程，与windows下的计划任务类似，当安装完成
		 操作系统后默认会安装此服务，并且会自动启动crond进程，该进程会定期检查是否有要执行的
		 任务，如果有，则自动执行；

            需要注意的是：crontab定时任务是在linux系统环境特定路径中，特定脚本、特定的语法添加
         定时任务，而不是通过在应用程序中写代码实现，并且系统默认配置有cron运行日志，出现错误时，
         可以到系统的日志文件夹中查看对应的日志文件。
	 3）apschedule -- 
            APScheduler是基于Jave的Quartz的python定时任务框架，实现了Quartz的所有功能，
         支持基于周期时间、日期、固定时间以及linux crontab类型的任务，并且支持多种方式持久
         化任务数据，如Memory,MongoDB,SQLAlchemy,Redis,ZooKeeper等，支持在程序中动态删
         除、添加、更新定时任务等操作，主要用于定时任务调度，功能完善、可靠。
	 4）celery -- 
            celery是一个简单、灵活且可靠的，可以处理大量消息的分布式系统，同时也支持任务调
         度，celery本身并不提供消息队列服务，一般要与RabbitMQ，Redis等消息中间件集成，所以
         配置和使用起来相对其他两种方式更加重量级，侧重点也不一样，主要专注于实时处理的异步任
         务队列，如一些耗时操作，发邮件、短信、音频视频处理、消息推送等等，一般情况下，系统比较大，需要用到celery进行异步任务处理，同时需要定时任务，可以借助celery实现定时任务,
         如果项目中单纯的只是对定时任务有需求，建议使用APSchedule；
## 二：schedule模块
**pip install schedule**

	官方示例：
	
		import schedule
		import time
		 
		def job():
		    print("I'm working...")
		 
		schedule.every(10).minutes.do(job)
		schedule.every().hour.do(job)
		schedule.every().day.at("10:30").do(job)
		schedule.every(5).to(10).days.do(job)
		schedule.every().monday.do(job)
		schedule.every().wednesday.at("13:15").do(job)
		 
		while True:
		    schedule.run_pending()
		    time.sleep(1)
## 三： linux系统定时任务：crontab -e 
### a. cron服务的状态
要使用 cron 服务，必须安装vixie-cron RPM 软件包，而且必须在运行 crond 服务。要判定该软件包是否已安装，使用 rpm -q vixie-cron命令。要判定该服务是否在运行，使用 /sbin/service crond status 命令。

	cron是linux的内置服务，可以用以下的方法启动、关闭这个服务：
	
	/sbin/service crondstart //启动服务
	/sbin/service crondstop //关闭服务
	/sbin/service crondrestart //重启服务
	/sbin/service crondreload //重新载入配置
### b. linux下两种任务调度方式 -- 系统任务调度和用户任务调度；
**无论是那种方式，调度任务配置文件中每一行就可以对应配置一个调度任务**

	系统任务调度 -- /etc/crontab文件中配置调度任务，只有root用户能用
	比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，就是系统任务调度配置文件；
	
	用户调度任务 -- crontab -e命令，所有用户都能用，任务自动写入/var/spool/cron/username中
	用户自定义自己的调度任务；
	
		crontab [-u uaername] [-l/-e/-r] -- 
			-u  ： 只有root能使用该选项，为指定的用户创建/移出crontab任务；
			-e  : 编辑crontab任务(创建或者移出)
			-l  ：查看crontab任务
			-r  ：清空当前用户所有的crontab任务（移出某个任务，用-e）

### c. 语法格式
	crontab定时任务每项工作 (每行)的命令格式有六个栏位，前五个都是时间，最后一个是命令：
		第一个栏位： 代表分钟（0-59或者*）
		第二个栏位： 代表小时（0-23或者*）
		第三个栏位： 代表日期（1-31或者*）
		第四个栏位： 代表月份（1-12或者*）
		第五个栏位： 代表星期（0-7或者*，其中0和7都代表星期天）
		第六个栏位： 代表任务命令
	
		前五个栏位的辅助字符：
		    *（星号） -- 代表任何时刻
		   ，（逗号） -- 代表分割时段的意思（多个时刻）
		    -（减号） -- 代表一段时间范围内
		    /(斜线) -- 代表每隔单位时间间隔
	
		以下几个crontab定时任务：
				0 3,6 * * * command   -- 3：00和6：00执行command
				20 8-12 * * * command  -- 8点到12点之间的每小时20分斗进行command
				*/5 * * * * command  -- 没五分钟进行一次command（0-59/5 * * * * command）
	    注意： 日月和周循环不能同时出现，系统可能会错误的执行
## 四：APSchedule模块
**pip install apscheduler**
### 1. APSchedule调度系统的五个组成部分：
* 调度器(scheduler)：

        通常情况下使用调度器配置储存器、触发器和执行器，以及任务的添加、修改、删除等；
* 存储器（jod store）:

        存储被调度的作业，默认的作业存储是把作业保存在内存中，可以保存在数据库中，持久
        化保存作业的数据时被序列化，并在加载时被反序列化，调度器不能分享同一个作业的存储；
* 触发器（trigger）:

        调度的逻辑，如何调度，每一个作业任务都有自己的触发器，触发器是无状态的；
* 执行器（executor）:

        处理作业的运行，通过在作用中提交制定的可调用对象到一个线程或者进程池来运行，当
        作业完成时，通知调度器；
* 任务函数（job）: 

        实现作业任务本身的业务逻辑，通俗的说就是这个任务要做些什么事；
### 2. 各组成部分详解：
#### a. 触发器：有interval/date/cron三种触发方式
######  1) interval -- 按一定时间间隔周期性触发任务，参数如下：
*  weeks (int) – 星期
*  days (int) – 天
*  hours (int) – 小时
*  minutes (int) – 分钟
*  seconds (int) – 秒钟
*  start_date (datetime|str) – 开始时间
*  end_date (datetime|str) – 结束时间
*  timezone (datetime.tzinfo|str) – 用于日期、时间计算的时区
*  jitter (int|None) – advance or delay the job execution by jitter seconds at most

指定一个时间区间，在某个时间区间内执行任务，如下：

 	sched.add_job(job_function, 'interval', hours=2, start_date='2018-01-10 09:30:00', end_date='2018-06-15 11:00:00')
######  2） cron -- 按指定时间周期性触发任务（类似linux的crontab），参数如下：
* year (int|str) – 4-digit year(4位数的年份)
* month (int|str) – month (1-12)
* day (int|str) – day of the (1-31)
* week (int|str) – ISO week (1-53)
* day_of_week (int|str) – number or name of weekday (0-6 or mon,tue,wed,thu,fri,sat,sun)
* hour (int|str) – hour (0-23)
* minute (int|str) – minute (0-59)
* second (int|str) – second (0-59)
* start_date (datetime|str) – earliest possible date/time to trigger on (inclusive)
* end_date (datetime|str) – latest possible date/time to trigger on (inclusive)
* timezone (datetime.tzinfo|str) – time zone to use forthe date/time calculations * * (defaults to scheduler timezone)
* jitter (int|None) – advance or delay the job execution by jitter seconds at most

当前任务会在 6、7、8、11、12 月的第三个周五的 0、1、2、3 点执行，如下：

    sched.add_job(job_function, 'cron', month='6-8,11-12', day='3rd fri', hour='0-3')
######  3） date -- 按指定时间触发任务，只执行一次，参数如下：
* run_date (datetime|str) – 开始执行的时间；
* timezone (datetime.tzinfo|str) – 用于日期、时间计算的时区；

run_date参数指定任务触发执行的时间，如下：

    @sched.scheduled_job('date', id='my_job', run_date='2018-01-23 18:25:30')
#### b. 存储器：持久化任务数据时，有以下几种backend方式

* MemoryJobStore：没有序列化，jobs就存在内存里，增删改查也都是在内存中操作
* SQLAlchemyJobStore：所有sqlalchemy支持的数据库都可以做为backend，增删改查操作转化为对应 backend的sql语句
* MongoDBJobStore：用mongodb作backend
* rethinkdb：用rethinkdb作backend
* RedisJobStore: 用redis作backend
* ZooKeeperJobStore：用ZooKeeper做backend
#### c. 执行器：任务调度的执行方式有以下几种：

* debug
* gevent
* pool(max_workers=10)
* twisted

#### d. 调度器：由于IO模型不同，可以有以下多种实现调度的方式：
	1) BlockingScheduler:
            main_loop在当前进程主线程内运行，任务start后会阻塞当前线程，这种方式是通过一
            个threading.Event条件变量对象完成scheduler的定时唤醒；
	2) BackgroundScheduler:
            和BlockingScheduler基本一样，但是main_loop是在子线程中执行，start后不会阻
            塞主线程；
	3) AsyncIOScheduler：
           使用asyncio作为IO模型的scheduler，和AsyncIOExecutor配合使用，用asynio中
           event_loop的call_later完成定时唤醒；
	4) GeventScheduler：
           和BlockingScheduler基本一样，使用gevent作为IO模型，和GeventExecutor配合使用；
	5) QtScheduler：使用QTimer完成定时唤醒；
	6) TornadoScheduler：使用tornado的IO模型，用ioloop.add_timeout完成定时唤醒；
	7) TwistedScheduler：配合TwistedExecutor，用reactor.callLater完成定时唤醒；
    
    代码示例如下：

        BlockingScheduler简单示例（不做任务数据持久化）：

		from apscheduler.schedulers.blocking import BlockingScheduler
		def my_job():
		    print 'hello world'
		  
		scheduler = BlockingScheduler()
		scheduler.add_job(my_job, 'interval', seconds=5)
		scheduler.start()


		BackgroundScheduler简单示例（不做任务数据持久化）：
		
		from apscheduler.schedulers.background import BackgroundScheduler
		 
		def job3():
		    print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())))
		    print("I'm working job_3")
		 
		scheduler = BackgroundScheduler()
		scheduler.add_job(job3, 'interval', seconds=30)　　#间隔30秒钟执行一次
		scheduler.start()
#### e: 调度器和任务的动态操作（更详情信息参照官方文档）：
**官方文档：https://apscheduler.readthedocs.io/en/3.0/modules/schedulers/base.html#apscheduler.schedulers.base.BaseScheduler**

    示例代码：

	import datetime
	from apscheduler.schedulers.blocking import BlockingScheduler
	
	def aps_test():
	   print datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), '你好'
	
	scheduler = BlockingScheduler()
	job= scheduler.add_job(func=aps_test, trigger='cron', second='*/5')
	scheduler.start()
    
	1） 添加任务：
        用scheduler.add_job(）方法或者是 @scheduler.scheduled_job()装饰器装饰任务函数
	2） 移除任务：
		job = scheduler.add_job(myfunc, 'interval', minutes=2)
		job.remove()
		# 如果有多个任务序列的话可以给每个任务设置ID号，可以根据ID号选择清除对象，
        # 且remove放到start前才有效
		scheduler.add_job(myfunc, 'interval', minutes=2, id='my_job_id')
		scheduler.remove_job('my_job_id')
		scheduler.remove_all_jobs(jobstore=None) # 移除指定作业存储区内所有作业，None则删除所有
	3） 暂停、恢复任务：
		job = scheduler.add_job(myfunc, 'interval', minutes=2)
		# 根据任务实例
		job.pause()
		job.resume()
		
		# 根据任务id暂停
		scheduler.add_job(myfunc, 'interval', minutes=2, id='my_job_id')
		scheduler.pause_job('my_job_id')
		scheduler.resume_job('my_job_id')
	4） 获取任务列表：
		获得调度作业的列表，可以使用get_jobs()来完成，它会返回所有的job实例,
		或者使用print_jobs()来输出所有格式化的作业列表。也可以利用get_job(任务ID)
		获取指定任务的作业列表

		scheduler.get_job(job_id='123')
		scheduler.get_jobs()
        scheduler.print_jobs(jobstore=None, out=sys.stdout) # 传入文件参数，将结果输出到指定文件
	5） 任务的重设：scheduler.reschedule_job('my_job_id', trigger='cron', minute='*/5')
	6） 任务的修饰：job.modify(max_instances=6, name='Alternate name')
	7） 开启调度器：scheduler.start()
    8） 关闭调度器：scheduler.shotdown(wait=True | False)
    9） 删除作业存储区：scheduler.remove_jobstore(alias, shutdown=True)
    10) 移除事件监听器：scheduler.remove_listener(callback)
    11) 通知调度器，可能有要执行的任务： scheduler.wakeup() # 触发器_process_jobs()以特定于实现的方式运行
    12) 给调度器设置日志文件：scheduler._logging = logger # logger是logging模块的日志对象
#### f: 如何写一个比较完善的任务调度（将业务数据持久化，监听任务意外状态等）：
**给任务配日志，或者有时任务中的数据需要持久化，或者如果出现意外任务出错等情况**

	import datetime
	import logging
	from pytz import utc
    from pymongo import MongoClient
	from apscheduler.schedulers.background import BackgroundScheduler
	from apscheduler.jobstores.mongodb import MongoDBJobStore
    from apscheduler.jobstores.redis import RedisJobStore
	from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
	from apscheduler.executors.pool import ThreadPoolExecutor, ProcessPoolExecutor
	from apscheduler.events import EVENT_JOB_MAX_INSTANCES, EVENT_JOB_ERROR, EVENT_JOB_MISSED

	# 配置日志
	logging.basicConfig(level=logging.INFO,
	                    format='%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s',
	                    datefmt='%Y-%m-%d %H:%M:%S',
	                    filename='sechduler_log.txt',
	                    filemode='a')

	# 配置作业存储器
	client = MongoClient(host='127.0.0.1', port=27017)
	pool = redis.ConnectionPool(host='127.0.0.1', port=16379)
	jobstores = {
	    'mongo': MongoDBJobStore(collection='job', database='test', client=client),
	    'redis': RedisJobStore(connection_pool=pool),
	    'default': MemoryJobStore(),
	    'default_test': MemoryJobStore()
	}

    # 配置执行器：默认线程池方式，尽量设置大一点，这个数是执行任务的实际并发数，
    # 如果设置的小了而job添加的比较多，可能出现丢失调度的情况
	executors = {
	    'default': ThreadPoolExecutor(200),
	    'processpool': ProcessPoolExecutor(10)
	}

    # 配置任务管理参数
    # coalesce：Trueb表示如果系统挂掉又恢复后，这段时间本来该执行3次任务，恢复后只执行一次；
                Flase表示按原计划执行
    # max_instances：表示同一时间能运行该job实例的个数
    # misfire_grace_time：一个job实例某种原因在规定时间没有运行，再次运行时的最大超时时间，超过则不运行
	job_defaults = {
	    'coalesce': True, 
	    'max_instances': 1,
	    'misfire_grace_time': 60
	}

	def my_job(x):
	    print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), x)

	def my_listener(event):
	    if event.exception:
	        print('任务出错了！！！！！！')
	    else:
	        print('任务照常运行...')

	scheduler = BackgroundScheduler(jobstores=jobstores, executors=executors, job_defaults=job_defaults, timezone=utc)
    scheduler.add_job(func=my_job, args=('循环任务my_job',), trigger='interval', seconds=3, id='interval_task')
    scheduler.add_listener(my_listener, EVENT_JOB_EXECUTED | EVENT_JOB_ERROR)
    scheduler._logger = logging
    scheduler.start()

## 五：celery异步任务分布式系统 
**celery主要有两个应用场景：重点是异步任务的处理，其次是定时任务**
### 1. 架构组成
	 a. 消息中间件（broker） -- celery本身不提供消息队列服务，与RabbitMQ，Redis等三方消息中间件可以灵活的集成；
	 b. 任务执行单元(worker) -- worker并发运行在celery分布式系统的节点中；
	 c. 任务存储（store）-- 允许不同的方式存储任务的结果，如redis,AMQP等；
### 2. 安装
		安装celery -- pip install celery
		安装消息队列 -- redis服务或者RabbitMQ
		django中使用celery -- pip install django-celery
### 3. 异步消息任务
### 4. 定时任务
### 5. django中使用celery